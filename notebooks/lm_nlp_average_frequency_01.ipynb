{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f792fc",
   "metadata": {
    "id": "37f792fc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import dtale\n",
    "import pymongo\n",
    "import csv\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ad2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "\n",
    "    \"\"\"import data from MongoDB\"\"\"\n",
    "\n",
    "    myclient = pymongo.MongoClient(\"mongodb+srv://lucas-deepen:DSIqP935gtFobYc2@cluster0.ixkyxa7.mongodb.net/?retryWrites=true&w=majority\")\n",
    "    mydb = myclient[\"cleanpapers\"]\n",
    "    mycol = mydb[\"cleanedf\"]\n",
    "    mydoc = mycol.find({}, {\"_id\":1,\"articleTitle\":1,\"abstract\":1,\"pubDate\":1,\"affiliations\":1})\n",
    "\n",
    "    print('----------Data imported----------')\n",
    "\n",
    "    return mydoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2efc641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe(mydoc,length=50000):\n",
    "\n",
    "    \"\"\"convert mongodb data to dataframe (full = 132820 rows)\"\"\"\n",
    "    \n",
    "    # data to dataframe and limit length\n",
    "    print('start')\n",
    "    df = pd.DataFrame(list(mydoc)).set_index(['_id'])\n",
    "    print('finished')\n",
    "    df = df[df.abstract != '.'].iloc[:length,:]\n",
    "\n",
    "    # extract year from the pubDate column\n",
    "\n",
    "    df['pubDate'] = df['pubDate'].str.extract(r'(\\d{4})')\n",
    "\n",
    "    print ('----------DataFrame created----------')\n",
    "\n",
    "    print (df.head(15))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f649db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "\n",
    "    \"\"\"cleaning function for the abstract\"\"\"\n",
    "\n",
    "    # transform abtract words into lower case\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove punctuations\n",
    "\n",
    "    for punctuation in string.punctuation:\n",
    "\n",
    "        text = text.replace(punctuation,'')\n",
    "\n",
    "    # remove digits\n",
    "\n",
    "    text = ''.join(char for char in text if not char.isdigit())\n",
    "\n",
    "    # tokenize sentences\n",
    "\n",
    "    tokenized_text = word_tokenize(text)\n",
    "\n",
    "    # remove stop words\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "    tokenized_sentence_cleaned = [w for w in tokenized_text\n",
    "                                if not w in stop_words]\n",
    "\n",
    "    # standardize verbs\n",
    "\n",
    "    verb_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"v\")\n",
    "            for word in tokenized_sentence_cleaned]\n",
    "\n",
    "    # standardize nouns\n",
    "\n",
    "    noun_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"n\")  # n --> nouns\n",
    "            for word in verb_lemmatized]\n",
    "\n",
    "    # re-join list into sentence\n",
    "\n",
    "    cleaned_txt = \" \".join(noun_lemmatized)\n",
    "\n",
    "    return cleaned_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18d1991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df):\n",
    "\n",
    "    \"\"\"generate tokenized dataframe\"\"\"\n",
    "\n",
    "    df_ = df.copy()\n",
    "\n",
    "    # apply clean function to abstracts\n",
    "\n",
    "    df_.abstract = df_.abstract.astype(str).apply(cleaning)\n",
    "\n",
    "    print ('----------Abstract cleaned----------')\n",
    "\n",
    "    # intitialize vectorizer model\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=False,\n",
    "                                analyzer='word',\n",
    "                                stop_words='english',\n",
    "                                max_df=0.6,min_df=15,\n",
    "                                token_pattern=r'(?u)\\b[A-Za-z]{4,}\\b',\n",
    "                                max_features=10000)\n",
    "\n",
    "    # fit_transform abstract\n",
    "\n",
    "    tfidf_abstract = tfidf_vectorizer.fit_transform(df_.abstract)\n",
    "\n",
    "    # create data frame with columns names\n",
    "\n",
    "    weighted_words = pd.DataFrame(tfidf_abstract.toarray(),\n",
    "                columns = tfidf_vectorizer.get_feature_names(),index=df_.index).round(2)\n",
    "\n",
    "    print ('----------Abstract tokenized----------')\n",
    "\n",
    "    print (weighted_words.head(15))\n",
    "\n",
    "    return weighted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47f7b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(token,words=['brain','mouse','animal','image','vivo','injury','intravital','voltage','circuit','neuronal','multiphoton','optogenetics','preclinical']):\n",
    "\n",
    "    \"\"\"rank abstracts based on chosen words\"\"\"\n",
    "\n",
    "    token_df = token.copy()\n",
    "\n",
    "    # clean tokenized data frame\n",
    "\n",
    "    selected_tokens = token_df[words].replace('',0).astype(float)\n",
    "\n",
    "    # remove rows with only 0 results\n",
    "\n",
    "    selected_tokens = selected_tokens.loc[~(selected_tokens==0).all(axis=1)]\n",
    "\n",
    "    # create count columns (1 - chosen word was encountered / 0 - chosen word was not encountered)\n",
    "\n",
    "    columns = selected_tokens.columns\n",
    "\n",
    "    length_words = selected_tokens.shape[1]\n",
    "\n",
    "    for index, row in selected_tokens.iterrows():\n",
    "\n",
    "        for column in columns:\n",
    "\n",
    "            new_column = f'{column}_count'\n",
    "\n",
    "            if row[column] > 0:\n",
    "\n",
    "                selected_tokens.loc[index, new_column] = 1\n",
    "\n",
    "            elif row[column] == 0:\n",
    "\n",
    "                selected_tokens.loc[index, new_column] = 0\n",
    "\n",
    "    # get average frequency of chosen words\n",
    "\n",
    "    selected_tokens['mean'] = (selected_tokens[list(columns)].sum(axis=1)) / length_words\n",
    "\n",
    "    # get how many chosen words were encountered\n",
    "\n",
    "    selected_tokens['count'] = selected_tokens.iloc[: , length_words:-1].sum(axis=1)\n",
    "\n",
    "    # sort rank by 1. how many chosen words were encountered and 2. average frequency of chosen words\n",
    "\n",
    "    df_rank = selected_tokens.sort_values(by=['count','mean'],ascending=False)[['count','mean']]\n",
    "\n",
    "    # remove rows with only 0 values\n",
    "\n",
    "    df_rank = df_rank.loc[~(df_rank==0).all(axis=1)]\n",
    "\n",
    "    print ('----------Abstracts ranked----------')\n",
    "\n",
    "    print (df_rank.head(15))\n",
    "\n",
    "    return df_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6a75232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34369928</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35478249</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.073077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34411280</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.106154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31043747</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23183856</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.060769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27147326</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846334</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35842308</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35291442</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35129211</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32569 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean\n",
       "_id                      \n",
       "34369928    9.0  0.100000\n",
       "35478249    9.0  0.073077\n",
       "34411280    8.0  0.106154\n",
       "31043747    8.0  0.080000\n",
       "23183856    8.0  0.060769\n",
       "...         ...       ...\n",
       "27147326    1.0  0.001538\n",
       "1846334     1.0  0.001538\n",
       "35842308    1.0  0.001538\n",
       "35291442    1.0  0.001538\n",
       "35129211    1.0  0.001538\n",
       "\n",
       "[32569 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4830232e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Data imported----------\n"
     ]
    }
   ],
   "source": [
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c37f676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "finished\n",
      "----------DataFrame created----------\n",
      "                                                   abstract  \\\n",
      "_id                                                           \n",
      "34314384  Intracortical microelectrode arrays (MEA) can ...   \n",
      "33996894  Medulloblastoma is the most common malignant c...   \n",
      "33862118  Nod-like receptor family pyrin domain containi...   \n",
      "33691255  Mice with chronic cochlear implants can signif...   \n",
      "33332038  An Auditory Brainstem Implant (ABI) is a techn...   \n",
      "31201186  Tinnitus may have a very severe impact on the ...   \n",
      "35509538  Manufacturing of customized three-dimensional ...   \n",
      "35024600  Injectable hydrogel has the advantage to fill ...   \n",
      "34425566  The evaluation of the long-term stability of E...   \n",
      "33762926  Mitochondria are organelles responsible for bi...   \n",
      "33647494  Evolutions in cranioplasty have allowed for th...   \n",
      "33431445  A 42-year-old woman presented with fever, left...   \n",
      "33318954  An estimated 3.8 million traumatic brain injur...   \n",
      "33025785  Modern development of flexible electronics has...   \n",
      "35961580  Gut microbiota alterations might affect the de...   \n",
      "\n",
      "                                               articleTitle pubDate  \\\n",
      "_id                                                                   \n",
      "34314384  Neuropathological effects of chronically impla...    2021   \n",
      "33996894  Veliparib Is an Effective Radiosensitizing Age...    2021   \n",
      "33862118  The NLRP3-related inflammasome modulates pain ...    2021   \n",
      "33691255  Development of a chronically-implanted mouse m...    2021   \n",
      "33332038                            [Hearing without ears].    2020   \n",
      "31201186  An auditory brainstem implant for treatment of...    2019   \n",
      "35509538  Customized alloplastic cranioplasty of large b...    2022   \n",
      "35024600  Injectable hyaluronic acid hydrogel loaded wit...    2022   \n",
      "34425566  Long-term stability of the chronic epidural wi...    2021   \n",
      "33762926  Mitochondrial Behavior in Axon Degeneration an...    2021   \n",
      "33647494  Cranioplasty Using Customized 3-Dimensional-Pr...    2021   \n",
      "33431445  Skull base osteomyelitis with secondary cavern...    2021   \n",
      "33318954     An implantable helmet for studying repeat TBI.    2020   \n",
      "33025785  Conductive Hydrogel for a Photothermal-Respons...    2020   \n",
      "35961580  Microbiota-derived metabolite Indoles induced ...    2022   \n",
      "\n",
      "                                               affiliations  \n",
      "_id                                                          \n",
      "34314384  Wu Tsai Neurosciences Institute, Stanford Univ...  \n",
      "33996894  Wu Tsai Neurosciences Institute, Stanford Univ...  \n",
      "33862118  Wu Tsai Neurosciences Institute, Stanford Univ...  \n",
      "33691255  Wu Tsai Neurosciences Institute, Stanford Univ...  \n",
      "33332038  Wu Tsai Neurosciences Institute, Stanford Univ...  \n",
      "31201186  Wu Tsai Neurosciences Institute, Stanford Univ...  \n",
      "35509538  Department of Mechanical Engineering, American...  \n",
      "35024600  Department of Mechanical Engineering, American...  \n",
      "34425566  Department of Mechanical Engineering, American...  \n",
      "33762926  Department of Mechanical Engineering, American...  \n",
      "33647494  Department of Mechanical Engineering, American...  \n",
      "33431445  Department of Mechanical Engineering, American...  \n",
      "33318954  Department of Mechanical Engineering, American...  \n",
      "33025785  Department of Mechanical Engineering, American...  \n",
      "35961580  Institute of Pulmonary Disease, Guangzhou Ches...  \n"
     ]
    }
   ],
   "source": [
    "df = dataframe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eac196e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Abstract cleaned----------\n",
      "----------Abstract tokenized----------\n",
      "          abandon  abbreviate  abca  abcd  abdomen  abdominal  aberrant  \\\n",
      "_id                                                                       \n",
      "34314384      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "33996894      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "33862118      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "33691255      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "33332038      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "31201186      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "35509538      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "35024600      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "34425566      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "33762926      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "33647494      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "33431445      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "33318954      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "33025785      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "35961580      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
      "\n",
      "          aberrantly  aberration  aberrationcorrected  ...  youth  zealand  \\\n",
      "_id                                                    ...                   \n",
      "34314384         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "33996894         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "33862118         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "33691255         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "33332038         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "31201186         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "35509538         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "35024600         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "34425566         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "33762926         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "33647494         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "33431445         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "33318954         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "33025785         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "35961580         0.0         0.0                  0.0  ...    0.0      0.0   \n",
      "\n",
      "          zebra  zebrafish  zero  zinc  zone  zoom  zscore  zscores  \n",
      "_id                                                                  \n",
      "34314384    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "33996894    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "33862118    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "33691255    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "33332038    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "31201186    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "35509538    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "35024600    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "34425566    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "33762926    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "33647494    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "33431445    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "33318954    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "33025785    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "35961580    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
      "\n",
      "[15 rows x 10000 columns]\n"
     ]
    }
   ],
   "source": [
    "token = tokenize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "670761b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Abstracts ranked----------\n",
      "          count      mean\n",
      "_id                      \n",
      "34369928    9.0  0.100000\n",
      "35478249    9.0  0.073077\n",
      "34411280    8.0  0.106154\n",
      "31043747    8.0  0.080000\n",
      "23183856    8.0  0.060769\n",
      "34636430    7.0  0.100769\n",
      "27615186    7.0  0.090000\n",
      "30517041    7.0  0.082308\n",
      "35718324    7.0  0.079231\n",
      "25411462    7.0  0.076923\n",
      "32717641    7.0  0.076154\n",
      "26052270    7.0  0.072308\n",
      "23469209    7.0  0.071538\n",
      "29501684    7.0  0.070769\n",
      "35115567    7.0  0.070000\n"
     ]
    }
   ],
   "source": [
    "ranked = rank(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f506b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'brain','mouse','animal','image','vivo','injury','intravital','voltage','circuit','neuronal','multiphoton','optogenetics','preclinical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afbbab52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Imaging neuronal activities at single-cell resolution in awake behaving animals is a very powerful approach for the investigation of neural circuit functions in systems neuroscience. However, high absorbance and scattering of light in mammalian tissue limit intravital imaging mostly to superficial brain regions, leaving deep-brain areas, such as the hippocampus, out of reach for optical microscopy. In this video, we show the preparation and implantation of the custom-made imaging window to enable chronic in vivo imaging of the dorsal hippocampal CA1 region in head-fixed behaving mice. The custom-made window is supplemented with an infusion cannula that allows targeted delivery of viral vectors and drugs to the imaging area. By combining this preparation with wide-field imaging, we performed a long-term recording of neuronal activity using a fluorescent calcium indicator from large subsets of neurons in behaving mice over several weeks. We also demonstrated the applicability of this preparation for voltage imaging with single-spike resolution. High-performance genetically encoded indicators of neuronal activity and scientific CMOS cameras allowed the recurrent visualization of subcellular morphological details of single neurons at high temporal resolution. We also discuss the advantages and potential limitations of the described method and its compatibility with other imaging techniques.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[ranked.index[0]]['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76767a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26db5aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Data imported----------\n"
     ]
    }
   ],
   "source": [
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "df = dataframe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0111f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year']=df['pubDate'].str.extract(r'(\\d{4})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9995e2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021    51141\n",
       "2022    46252\n",
       "2020    13970\n",
       "2019     2954\n",
       "2018     2604\n",
       "2017     1981\n",
       "2015     1833\n",
       "2016     1785\n",
       "2014     1616\n",
       "2013     1170\n",
       "2012      841\n",
       "2011      724\n",
       "2010      602\n",
       "2009      544\n",
       "2008      531\n",
       "2007      438\n",
       "2006      406\n",
       "2004      337\n",
       "2005      326\n",
       "2003      280\n",
       "2002      265\n",
       "2000      221\n",
       "2001      216\n",
       "1996      204\n",
       "1999      193\n",
       "1998      185\n",
       "1997      176\n",
       "1995      143\n",
       "1994      129\n",
       "1993      108\n",
       "1991       90\n",
       "1992       84\n",
       "1990       76\n",
       "1989       65\n",
       "1987       47\n",
       "1988       45\n",
       "1984       34\n",
       "1986       27\n",
       "1985       27\n",
       "2023       26\n",
       "1981       23\n",
       "1983       20\n",
       "1982       15\n",
       "1976       12\n",
       "1975       11\n",
       "1977       10\n",
       "1978       10\n",
       "1980        9\n",
       "1979        8\n",
       "1968        2\n",
       "1973        1\n",
       "1971        1\n",
       "1974        1\n",
       "1972        1\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56072058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pubDate']=df['pubDate'].str.extract(r'(\\d{4})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb2f3281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>articleTitle</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35906351</th>\n",
       "      <td>MicroRNAs have been recognized as important re...</td>\n",
       "      <td>Trehalose Attenuates Learning and Memory Impai...</td>\n",
       "      <td>2022</td>\n",
       "      <td>P.R. China., P.R. China., P.R. China., P.R. Ch...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34081908</th>\n",
       "      <td>Cell death events continuously challenge epith...</td>\n",
       "      <td>Collective ERK/Akt activity waves orchestrate ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Department of Ophthalmology, Stanford Universi...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34777045</th>\n",
       "      <td>The pandemic has highlighted the importance of...</td>\n",
       "      <td>Changes in Social, Romantic, and General Life ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>United Kingdom., United Kingdom., United Kingd...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35690493</th>\n",
       "      <td>Lewy Body Dementia is the second most frequent...</td>\n",
       "      <td>Recent advances in Lewy body dementia: A compr...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Department of Psychology, Pusan National Unive...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33862118</th>\n",
       "      <td>Nod-like receptor family pyrin domain containi...</td>\n",
       "      <td>The NLRP3-related inflammasome modulates pain ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Wu Tsai Neurosciences Institute, Stanford Univ...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34690623</th>\n",
       "      <td>Subclinical vitamin D (vitD) deficiency enhanc...</td>\n",
       "      <td>'Co-administration of vitamin D3 and  DG incr...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Department of Oncology and Molecular Medicine,...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34595791</th>\n",
       "      <td>There is a growing interest in the neuroscienc...</td>\n",
       "      <td>'Whole-brain high-resolution metabolite mappi...</td>\n",
       "      <td>2022</td>\n",
       "      <td>100101, China., 100101, China., 200031, China....</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34402739</th>\n",
       "      <td>Constraining knee flexion of non-disabled indi...</td>\n",
       "      <td>Compensatory Strategies Due to Knee Flexion Co...</td>\n",
       "      <td>2022</td>\n",
       "      <td>FL 33458., FL 33458., FL 33458.</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35332139</th>\n",
       "      <td>The staging and local management of breast can...</td>\n",
       "      <td>Intratumoral in vivo staging of breast cancer ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>J. Philip Kistler Stroke Research Center (V.P....</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34763266</th>\n",
       "      <td>To report the clinical outcome of nicotine exp...</td>\n",
       "      <td>Precision treatment with nicotine in autosomal...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Genoa, Italy., Genoa, Italy., Genoa, Italy., G...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   abstract  \\\n",
       "_id                                                           \n",
       "35906351  MicroRNAs have been recognized as important re...   \n",
       "34081908  Cell death events continuously challenge epith...   \n",
       "34777045  The pandemic has highlighted the importance of...   \n",
       "35690493  Lewy Body Dementia is the second most frequent...   \n",
       "33862118  Nod-like receptor family pyrin domain containi...   \n",
       "34690623  Subclinical vitamin D (vitD) deficiency enhanc...   \n",
       "34595791  There is a growing interest in the neuroscienc...   \n",
       "34402739  Constraining knee flexion of non-disabled indi...   \n",
       "35332139  The staging and local management of breast can...   \n",
       "34763266  To report the clinical outcome of nicotine exp...   \n",
       "\n",
       "                                               articleTitle pubDate  \\\n",
       "_id                                                                   \n",
       "35906351  Trehalose Attenuates Learning and Memory Impai...    2022   \n",
       "34081908  Collective ERK/Akt activity waves orchestrate ...    2021   \n",
       "34777045  Changes in Social, Romantic, and General Life ...    2021   \n",
       "35690493  Recent advances in Lewy body dementia: A compr...    2022   \n",
       "33862118  The NLRP3-related inflammasome modulates pain ...    2021   \n",
       "34690623   'Co-administration of vitamin D3 and  DG incr...    2021   \n",
       "34595791   'Whole-brain high-resolution metabolite mappi...    2022   \n",
       "34402739  Compensatory Strategies Due to Knee Flexion Co...    2022   \n",
       "35332139  Intratumoral in vivo staging of breast cancer ...    2022   \n",
       "34763266  Precision treatment with nicotine in autosomal...    2021   \n",
       "\n",
       "                                               affiliations  Year  \n",
       "_id                                                                \n",
       "35906351  P.R. China., P.R. China., P.R. China., P.R. Ch...  2022  \n",
       "34081908  Department of Ophthalmology, Stanford Universi...  2021  \n",
       "34777045  United Kingdom., United Kingdom., United Kingd...  2021  \n",
       "35690493  Department of Psychology, Pusan National Unive...  2022  \n",
       "33862118  Wu Tsai Neurosciences Institute, Stanford Univ...  2021  \n",
       "34690623  Department of Oncology and Molecular Medicine,...  2021  \n",
       "34595791  100101, China., 100101, China., 200031, China....  2022  \n",
       "34402739                    FL 33458., FL 33458., FL 33458.  2022  \n",
       "35332139  J. Philip Kistler Stroke Research Center (V.P....  2022  \n",
       "34763266  Genoa, Italy., Genoa, Italy., Genoa, Italy., G...  2021  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c705fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2022', '2021', '2020', '2019', '2023', '2018', '2017', '2016',\n",
       "       '2015', '2014', '2013', '2012', '2011', '2010', '2009', '2008',\n",
       "       '2007', '2001', '1998', '2006', '2005', '2002', '2004', '2003',\n",
       "       '1999', '2000', '1997', '1996', '1995', '1994', '1993', '1992',\n",
       "       '1991', '1990', '1989', '1988', '1987', '1986', '1985', '1984',\n",
       "       '1983', '1982', '1981', '1980', '1979', '1978', '1977', '1976',\n",
       "       '1975', '1973', '1971', '1974', '1972', '1968'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef458b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132820"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e6c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abstract = df[df.abstract != '.'].iloc[:df.shape[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc7a978d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132813"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abstract.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ac54e0e",
   "metadata": {
    "id": "0ac54e0e"
   },
   "outputs": [],
   "source": [
    "def clean_txt(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    for punctuation in string.punctuation:\n",
    "        \n",
    "        text = text.replace(punctuation,'')\n",
    "              \n",
    "    text = ''.join(char for char in text if not char.isdigit()) \n",
    "    \n",
    "    tokenized_text = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    tokenized_sentence_cleaned = [w for w in tokenized_text \n",
    "                                  if not w in stop_words]\n",
    "    \n",
    "    verb_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"v\")\n",
    "              for word in tokenized_sentence_cleaned]\n",
    "    \n",
    "    noun_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"n\")  # n --> nouns\n",
    "               for word in verb_lemmatized]\n",
    "        \n",
    "    return \" \".join(noun_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "757920e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abstract.abstract = df_abstract.abstract.astype(str).apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51ded210",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(use_idf=False, \n",
    "                                   analyzer='word', \n",
    "                                   stop_words='english',\n",
    "                                   max_df=0.6,min_df=15, \n",
    "                                   token_pattern=r'(?u)\\b[A-Za-z]{4,}\\b',\n",
    "                                   max_features=10000)\n",
    "\n",
    "tfidf_abstract = tfidf_vectorizer.fit_transform(df_abstract.abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4c74422",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_words = pd.DataFrame(tfidf_abstract.toarray(),\n",
    "                 columns = tfidf_vectorizer.get_feature_names(),index=df_abstract.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "380e0ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>abca</th>\n",
       "      <th>abcd</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>aberrant</th>\n",
       "      <th>aberrantly</th>\n",
       "      <th>aberration</th>\n",
       "      <th>aberrationcorrected</th>\n",
       "      <th>...</th>\n",
       "      <th>youth</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zebrafish</th>\n",
       "      <th>zero</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zscore</th>\n",
       "      <th>zscores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35912857</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35911768</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35911740</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35910379</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35909127</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34843225</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34843206</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34843176</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34843172</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34843070</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          abandon  abbreviate  abca  abcd  abdomen  abdominal  aberrant  \\\n",
       "_id                                                                       \n",
       "35912857      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
       "35911768      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
       "35911740      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
       "35910379      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
       "35909127      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
       "...           ...         ...   ...   ...      ...        ...       ...   \n",
       "34843225      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
       "34843206      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
       "34843176      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
       "34843172      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
       "34843070      0.0         0.0   0.0   0.0      0.0        0.0       0.0   \n",
       "\n",
       "          aberrantly  aberration  aberrationcorrected  ...  youth  zealand  \\\n",
       "_id                                                    ...                   \n",
       "35912857         0.0         0.0                  0.0  ...    0.0      0.0   \n",
       "35911768         0.0         0.0                  0.0  ...    0.0      0.0   \n",
       "35911740         0.0         0.0                  0.0  ...    0.0      0.0   \n",
       "35910379         0.0         0.0                  0.0  ...    0.0      0.0   \n",
       "35909127         0.0         0.0                  0.0  ...    0.0      0.0   \n",
       "...              ...         ...                  ...  ...    ...      ...   \n",
       "34843225         0.0         0.0                  0.0  ...    0.0      0.0   \n",
       "34843206         0.0         0.0                  0.0  ...    0.0      0.0   \n",
       "34843176         0.0         0.0                  0.0  ...    0.0      0.0   \n",
       "34843172         0.0         0.0                  0.0  ...    0.0      0.0   \n",
       "34843070         0.0         0.0                  0.0  ...    0.0      0.0   \n",
       "\n",
       "          zebra  zebrafish  zero  zinc  zone  zoom  zscore  zscores  \n",
       "_id                                                                  \n",
       "35912857    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
       "35911768    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
       "35911740    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
       "35910379    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
       "35909127    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
       "...         ...        ...   ...   ...   ...   ...     ...      ...  \n",
       "34843225    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
       "34843206    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
       "34843176    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
       "34843172    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
       "34843070    0.0        0.0   0.0   0.0   0.0   0.0     0.0      0.0  \n",
       "\n",
       "[50000 rows x 10000 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "534d05ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bowtie</th>\n",
       "      <td>1.410031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danish</th>\n",
       "      <td>1.534699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selfadminister</th>\n",
       "      <td>1.546328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sizespecific</th>\n",
       "      <td>1.548338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kinesiophobia</th>\n",
       "      <td>1.578462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuron</th>\n",
       "      <td>1719.887962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brain</th>\n",
       "      <td>1732.498938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell</th>\n",
       "      <td>2090.254145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <td>2815.215629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study</th>\n",
       "      <td>3067.462066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "bowtie             1.410031\n",
       "danish             1.534699\n",
       "selfadminister     1.546328\n",
       "sizespecific       1.548338\n",
       "kinesiophobia      1.578462\n",
       "...                     ...\n",
       "neuron          1719.887962\n",
       "brain           1732.498938\n",
       "cell            2090.254145\n",
       "patient         2815.215629\n",
       "study           3067.462066\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(weighted_words.sum()).sort_values(by=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70550cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brain</th>\n",
       "      <th>mouse</th>\n",
       "      <th>animal</th>\n",
       "      <th>image</th>\n",
       "      <th>vivo</th>\n",
       "      <th>injury</th>\n",
       "      <th>intravital</th>\n",
       "      <th>voltage</th>\n",
       "      <th>circuit</th>\n",
       "      <th>neuronal</th>\n",
       "      <th>multiphoton</th>\n",
       "      <th>optogenetics</th>\n",
       "      <th>preclinical</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35912857</th>\n",
       "      <td>0.287348</td>\n",
       "      <td>0.191565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35911768</th>\n",
       "      <td>0.060971</td>\n",
       "      <td>0.060971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35911740</th>\n",
       "      <td>0.475651</td>\n",
       "      <td>0.047565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35910379</th>\n",
       "      <td>0.051367</td>\n",
       "      <td>0.667765</td>\n",
       "      <td>0.051367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35909127</th>\n",
       "      <td>0.082549</td>\n",
       "      <td>0.165098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041274</td>\n",
       "      <td>0.041274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34843625</th>\n",
       "      <td>0.157676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34843461</th>\n",
       "      <td>0.095893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34843455</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34843364</th>\n",
       "      <td>0.105409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34843287</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32588 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             brain     mouse    animal     image      vivo    injury  \\\n",
       "_id                                                                    \n",
       "35912857  0.287348  0.191565  0.000000  0.000000  0.000000  0.095783   \n",
       "35911768  0.060971  0.060971  0.000000  0.000000  0.000000  0.060971   \n",
       "35911740  0.475651  0.047565  0.000000  0.000000  0.000000  0.000000   \n",
       "35910379  0.051367  0.667765  0.051367  0.000000  0.000000  0.000000   \n",
       "35909127  0.082549  0.165098  0.000000  0.000000  0.041274  0.041274   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "34843625  0.157676  0.000000  0.000000  0.157676  0.000000  0.000000   \n",
       "34843461  0.095893  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "34843455  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "34843364  0.105409  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "34843287  0.000000  0.000000  0.000000  0.072548  0.000000  0.000000   \n",
       "\n",
       "          intravital  voltage  circuit  neuronal  multiphoton  optogenetics  \\\n",
       "_id                                                                           \n",
       "35912857         0.0      0.0      0.0  0.000000          0.0           0.0   \n",
       "35911768         0.0      0.0      0.0  0.000000          0.0           0.0   \n",
       "35911740         0.0      0.0      0.0  0.000000          0.0           0.0   \n",
       "35910379         0.0      0.0      0.0  0.000000          0.0           0.0   \n",
       "35909127         0.0      0.0      0.0  0.000000          0.0           0.0   \n",
       "...              ...      ...      ...       ...          ...           ...   \n",
       "34843625         0.0      0.0      0.0  0.000000          0.0           0.0   \n",
       "34843461         0.0      0.0      0.0  0.000000          0.0           0.0   \n",
       "34843455         0.0      0.0      0.0  0.149487          0.0           0.0   \n",
       "34843364         0.0      0.0      0.0  0.000000          0.0           0.0   \n",
       "34843287         0.0      0.0      0.0  0.000000          0.0           0.0   \n",
       "\n",
       "          preclinical  \n",
       "_id                    \n",
       "35912857     0.000000  \n",
       "35911768     0.000000  \n",
       "35911740     0.000000  \n",
       "35910379     0.051367  \n",
       "35909127     0.000000  \n",
       "...               ...  \n",
       "34843625     0.000000  \n",
       "34843461     0.000000  \n",
       "34843455     0.000000  \n",
       "34843364     0.000000  \n",
       "34843287     0.000000  \n",
       "\n",
       "[32588 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_1 = weighted_words[['brain','mouse','animal','image','vivo','injury',\n",
    "                          'intravital','voltage','circuit','neuronal','multiphoton',\n",
    "                         'optogenetics','preclinical']].replace('',0).astype(float)\n",
    "\n",
    "#\n",
    "\n",
    "df_1_1 = df_1_1.loc[~(df_1_1==0).all(axis=1)]\n",
    "df_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70c6367e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>brain</th>\n",
       "      <th>mouse</th>\n",
       "      <th>animal</th>\n",
       "      <th>image</th>\n",
       "      <th>vivo</th>\n",
       "      <th>injury</th>\n",
       "      <th>intravital</th>\n",
       "      <th>voltage</th>\n",
       "      <th>circuit</th>\n",
       "      <th>neuronal</th>\n",
       "      <th>multiphoton</th>\n",
       "      <th>optogenetics</th>\n",
       "      <th>preclinical</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th>PMID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62f7b7e04c208a014ff2b53a</th>\n",
       "      <th>35912857</th>\n",
       "      <td>0.221163</td>\n",
       "      <td>0.147442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62f7b7e04c208a014ff2b53b</th>\n",
       "      <th>35911768</th>\n",
       "      <td>0.059339</td>\n",
       "      <td>0.059339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62f7b7e04c208a014ff2b53c</th>\n",
       "      <th>35911740</th>\n",
       "      <td>0.585206</td>\n",
       "      <td>0.058521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62f7b7e04c208a014ff2b53d</th>\n",
       "      <th>35910379</th>\n",
       "      <td>0.052414</td>\n",
       "      <td>0.681385</td>\n",
       "      <td>0.052414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62f7b7e04c208a014ff2b53e</th>\n",
       "      <th>35909127</th>\n",
       "      <td>0.087622</td>\n",
       "      <td>0.175243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62f8992ba179e2905ea47625</th>\n",
       "      <th>35726097</th>\n",
       "      <td>0.595491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62f8992ba179e2905ea47626</th>\n",
       "      <th>35726059</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62f8992ba179e2905ea47627</th>\n",
       "      <th>35726057</th>\n",
       "      <td>0.088736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62f8992ba179e2905ea47628</th>\n",
       "      <th>35726055</th>\n",
       "      <td>0.410152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62f8992ba179e2905ea47629</th>\n",
       "      <th>35726031</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181071</td>\n",
       "      <td>0.090536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20686 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      brain     mouse    animal  image  \\\n",
       "_id                      PMID                                            \n",
       "62f7b7e04c208a014ff2b53a 35912857  0.221163  0.147442  0.000000    0.0   \n",
       "62f7b7e04c208a014ff2b53b 35911768  0.059339  0.059339  0.000000    0.0   \n",
       "62f7b7e04c208a014ff2b53c 35911740  0.585206  0.058521  0.000000    0.0   \n",
       "62f7b7e04c208a014ff2b53d 35910379  0.052414  0.681385  0.052414    0.0   \n",
       "62f7b7e04c208a014ff2b53e 35909127  0.087622  0.175243  0.000000    0.0   \n",
       "...                                     ...       ...       ...    ...   \n",
       "62f8992ba179e2905ea47625 35726097  0.595491  0.000000  0.059549    0.0   \n",
       "62f8992ba179e2905ea47626 35726059  0.000000  0.102598  0.000000    0.0   \n",
       "62f8992ba179e2905ea47627 35726057  0.088736  0.000000  0.000000    0.0   \n",
       "62f8992ba179e2905ea47628 35726055  0.410152  0.000000  0.000000    0.0   \n",
       "62f8992ba179e2905ea47629 35726031  0.000000  0.181071  0.090536    0.0   \n",
       "\n",
       "                                       vivo    injury  intravital  voltage  \\\n",
       "_id                      PMID                                                \n",
       "62f7b7e04c208a014ff2b53a 35912857  0.000000  0.073721         0.0      0.0   \n",
       "62f7b7e04c208a014ff2b53b 35911768  0.000000  0.059339         0.0      0.0   \n",
       "62f7b7e04c208a014ff2b53c 35911740  0.000000  0.000000         0.0      0.0   \n",
       "62f7b7e04c208a014ff2b53d 35910379  0.000000  0.000000         0.0      0.0   \n",
       "62f7b7e04c208a014ff2b53e 35909127  0.043811  0.043811         0.0      0.0   \n",
       "...                                     ...       ...         ...      ...   \n",
       "62f8992ba179e2905ea47625 35726097  0.000000  0.000000         0.0      0.0   \n",
       "62f8992ba179e2905ea47626 35726059  0.000000  0.000000         0.0      0.0   \n",
       "62f8992ba179e2905ea47627 35726057  0.088736  0.000000         0.0      0.0   \n",
       "62f8992ba179e2905ea47628 35726055  0.000000  0.000000         0.0      0.0   \n",
       "62f8992ba179e2905ea47629 35726031  0.000000  0.000000         0.0      0.0   \n",
       "\n",
       "                                   circuit  neuronal  multiphoton  \\\n",
       "_id                      PMID                                       \n",
       "62f7b7e04c208a014ff2b53a 35912857      0.0  0.000000          0.0   \n",
       "62f7b7e04c208a014ff2b53b 35911768      0.0  0.000000          0.0   \n",
       "62f7b7e04c208a014ff2b53c 35911740      0.0  0.000000          0.0   \n",
       "62f7b7e04c208a014ff2b53d 35910379      0.0  0.000000          0.0   \n",
       "62f7b7e04c208a014ff2b53e 35909127      0.0  0.000000          0.0   \n",
       "...                                    ...       ...          ...   \n",
       "62f8992ba179e2905ea47625 35726097      0.0  0.000000          0.0   \n",
       "62f8992ba179e2905ea47626 35726059      0.0  0.000000          0.0   \n",
       "62f8992ba179e2905ea47627 35726057      0.0  0.177471          0.0   \n",
       "62f8992ba179e2905ea47628 35726055      0.0  0.000000          0.0   \n",
       "62f8992ba179e2905ea47629 35726031      0.0  0.000000          0.0   \n",
       "\n",
       "                                   optogenetics  preclinical  \n",
       "_id                      PMID                                 \n",
       "62f7b7e04c208a014ff2b53a 35912857           0.0     0.000000  \n",
       "62f7b7e04c208a014ff2b53b 35911768           0.0     0.000000  \n",
       "62f7b7e04c208a014ff2b53c 35911740           0.0     0.000000  \n",
       "62f7b7e04c208a014ff2b53d 35910379           0.0     0.052414  \n",
       "62f7b7e04c208a014ff2b53e 35909127           0.0     0.000000  \n",
       "...                                         ...          ...  \n",
       "62f8992ba179e2905ea47625 35726097           0.0     0.000000  \n",
       "62f8992ba179e2905ea47626 35726059           0.0     0.000000  \n",
       "62f8992ba179e2905ea47627 35726057           0.0     0.000000  \n",
       "62f8992ba179e2905ea47628 35726055           0.0     0.000000  \n",
       "62f8992ba179e2905ea47629 35726031           0.0     0.000000  \n",
       "\n",
       "[20686 rows x 13 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebb9e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_1_1.columns\n",
    "\n",
    "length_words = df_1_1.shape[1]\n",
    "    \n",
    "for index, row in df_1_1.iterrows():\n",
    "\n",
    "    for column in columns:\n",
    "\n",
    "        new_column = f'{column}_count'\n",
    "        \n",
    "\n",
    "        if row[column] > 0:\n",
    "            \n",
    "            df_1_1.loc[index, new_column] = 1\n",
    "\n",
    "\n",
    "        elif row[column] == 0:\n",
    "\n",
    "            df_1_1.loc[index, new_column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85a62b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_1_1['mean'] = (df_1_1[list(columns)].sum(axis=1)) / length_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "953fe2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_1['count'] = df_1_1.iloc[: , length_words:-1].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d64f3dc2",
   "metadata": {
    "id": "d64f3dc2",
    "outputId": "a931d832-e9f3-4185-8584-fc95e9be2734"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34369928</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.099216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35478249</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.074950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34411280</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.105912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31043747</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.081177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23183856</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.062378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27147326</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35291442</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846334</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35842308</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35129211</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32588 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean\n",
       "_id                      \n",
       "34369928    9.0  0.099216\n",
       "35478249    9.0  0.074950\n",
       "34411280    8.0  0.105912\n",
       "31043747    8.0  0.081177\n",
       "23183856    8.0  0.062378\n",
       "...         ...       ...\n",
       "27147326    1.0  0.001921\n",
       "35291442    1.0  0.001877\n",
       "1846334     1.0  0.001849\n",
       "35842308    1.0  0.001759\n",
       "35129211    1.0  0.001624\n",
       "\n",
       "[32588 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank = df_1_1.sort_values(by=['count','mean'],ascending=False)[['count','mean']]\n",
    "df_rank = df_rank.loc[~(df_rank==0).all(axis=1)]\n",
    "df_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e2d4365",
   "metadata": {
    "id": "5e2d4365",
    "outputId": "e54ff33f-d593-4e65-ed94-87da67ee1d0c",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34369928</th>\n",
       "      <td>Imaging neuronal activities at single-cell res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35478249</th>\n",
       "      <td>Recent advances combining two-photon calcium i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34411280</th>\n",
       "      <td>The brain consists of neural circuits, which a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31043747</th>\n",
       "      <td>A technology that simultaneously records membr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23183856</th>\n",
       "      <td>Traumatic Brain Injury (TBI) afflicts more tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34636430</th>\n",
       "      <td>Positron emission tomography (PET) allows biom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27615186</th>\n",
       "      <td>Optical imaging of voltage indicators is a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30517041</th>\n",
       "      <td>Traumatic brain injuries introduce functional ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35718324</th>\n",
       "      <td>Optogenetics has revolutionized the capability...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32717641</th>\n",
       "      <td>Recording the electrical activity of multiple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25411462</th>\n",
       "      <td>Genetically encoded voltage sensors expand the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26052270</th>\n",
       "      <td>Neuronal activity is dominated by synaptic inp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29501684</th>\n",
       "      <td>Traumatic brain injury (TBI) is to date one of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23469209</th>\n",
       "      <td>Synaptic levels of the monoamine neurotransmit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29341006</th>\n",
       "      <td>Since its discovery in the early 90s, BOLD sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35115567</th>\n",
       "      <td>Genetically encoded voltage indicators (GEVIs)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35156923</th>\n",
       "      <td>Optical control of neural ensemble activity is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23859961</th>\n",
       "      <td>Many people escape sudden death from ischemic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31068695</th>\n",
       "      <td>Neuronal-activity-dependent transcription coup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32667774</th>\n",
       "      <td>Polyneuropathy is a disease involving multiple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32116570</th>\n",
       "      <td>Electrical kindling, repeated brain stimulatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31732722</th>\n",
       "      <td>Multiple aspects of neural activity, from neur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31987494</th>\n",
       "      <td>Previous studies indicated the involvement of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21694695</th>\n",
       "      <td>Migraine and its transformation to chronic mig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26476852</th>\n",
       "      <td>Thanks to their flexibility, optical technique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34031611</th>\n",
       "      <td>The use of optogenetics to regulate neuronal a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35065250</th>\n",
       "      <td>Acute injuries or insults to the cortex, such ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22821441</th>\n",
       "      <td>Spreading depolarizations are a key event in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35698178</th>\n",
       "      <td>Intravital imaging via two-photon microscopy (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28566693</th>\n",
       "      <td>Non-invasive optical imaging of neuronal volta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23695972</th>\n",
       "      <td>Optogenetics is the optical control of neurona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33309867</th>\n",
       "      <td>The cerebral cortex has complex yet perfectly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34531329</th>\n",
       "      <td>In vivo time-lapse imaging has been a fruitful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16958584</th>\n",
       "      <td>Traumatic brain injury (TBI) damages the hippo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29986165</th>\n",
       "      <td>A major mystery of many types of neurological ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34893595</th>\n",
       "      <td>To better understand the input-output computat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31636534</th>\n",
       "      <td>Whole-brain volumetric microscopy techniques s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31758973</th>\n",
       "      <td>Voltage imaging is the next generation of func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32548365</th>\n",
       "      <td>Traumatic brain injury often leads to progress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21976493</th>\n",
       "      <td>Cortical compression can be a significant prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26954754</th>\n",
       "      <td>We present a motion-free system for microendos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19617885</th>\n",
       "      <td>To understand the cellular and circuit mechani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23545255</th>\n",
       "      <td>One of the main instigators leading to cell de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34354291</th>\n",
       "      <td>To understand neural circuit mechanisms underl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29748648</th>\n",
       "      <td>In vivo two-photon calcium imaging provides de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23142482</th>\n",
       "      <td>Multicellular neuronal activities should be in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28749338</th>\n",
       "      <td>Monitoring voltage dynamics in defined neurons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16958585</th>\n",
       "      <td>Traumatic brain injury is a leading cause of d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103345</th>\n",
       "      <td>In vivo calcium imaging is a powerful tool use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33779289</th>\n",
       "      <td>Traumatic brain injury (TBI) causes long-lasti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   abstract\n",
       "_id                                                        \n",
       "34369928  Imaging neuronal activities at single-cell res...\n",
       "35478249  Recent advances combining two-photon calcium i...\n",
       "34411280  The brain consists of neural circuits, which a...\n",
       "31043747  A technology that simultaneously records membr...\n",
       "23183856  Traumatic Brain Injury (TBI) afflicts more tha...\n",
       "34636430  Positron emission tomography (PET) allows biom...\n",
       "27615186  Optical imaging of voltage indicators is a pro...\n",
       "30517041  Traumatic brain injuries introduce functional ...\n",
       "35718324  Optogenetics has revolutionized the capability...\n",
       "32717641  Recording the electrical activity of multiple ...\n",
       "25411462  Genetically encoded voltage sensors expand the...\n",
       "26052270  Neuronal activity is dominated by synaptic inp...\n",
       "29501684  Traumatic brain injury (TBI) is to date one of...\n",
       "23469209  Synaptic levels of the monoamine neurotransmit...\n",
       "29341006  Since its discovery in the early 90s, BOLD sig...\n",
       "35115567  Genetically encoded voltage indicators (GEVIs)...\n",
       "35156923  Optical control of neural ensemble activity is...\n",
       "23859961  Many people escape sudden death from ischemic ...\n",
       "31068695  Neuronal-activity-dependent transcription coup...\n",
       "32667774  Polyneuropathy is a disease involving multiple...\n",
       "32116570  Electrical kindling, repeated brain stimulatio...\n",
       "31732722  Multiple aspects of neural activity, from neur...\n",
       "31987494  Previous studies indicated the involvement of ...\n",
       "21694695  Migraine and its transformation to chronic mig...\n",
       "26476852  Thanks to their flexibility, optical technique...\n",
       "34031611  The use of optogenetics to regulate neuronal a...\n",
       "35065250  Acute injuries or insults to the cortex, such ...\n",
       "22821441  Spreading depolarizations are a key event in t...\n",
       "35698178  Intravital imaging via two-photon microscopy (...\n",
       "28566693  Non-invasive optical imaging of neuronal volta...\n",
       "23695972  Optogenetics is the optical control of neurona...\n",
       "33309867  The cerebral cortex has complex yet perfectly ...\n",
       "34531329  In vivo time-lapse imaging has been a fruitful...\n",
       "16958584  Traumatic brain injury (TBI) damages the hippo...\n",
       "29986165  A major mystery of many types of neurological ...\n",
       "34893595  To better understand the input-output computat...\n",
       "31636534  Whole-brain volumetric microscopy techniques s...\n",
       "31758973  Voltage imaging is the next generation of func...\n",
       "32548365  Traumatic brain injury often leads to progress...\n",
       "21976493  Cortical compression can be a significant prob...\n",
       "26954754  We present a motion-free system for microendos...\n",
       "19617885  To understand the cellular and circuit mechani...\n",
       "23545255  One of the main instigators leading to cell de...\n",
       "34354291  To understand neural circuit mechanisms underl...\n",
       "29748648  In vivo two-photon calcium imaging provides de...\n",
       "23142482  Multicellular neuronal activities should be in...\n",
       "28749338  Monitoring voltage dynamics in defined neurons...\n",
       "16958585  Traumatic brain injury is a leading cause of d...\n",
       "30103345  In vivo calcium imaging is a powerful tool use...\n",
       "33779289  Traumatic brain injury (TBI) causes long-lasti..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[list(df_rank.index)][['abstract']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3e0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3453c303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Imaging neuronal activities at single-cell resolution in awake behaving animals is a very powerful approach for the investigation of neural circuit functions in systems neuroscience. However, high absorbance and scattering of light in mammalian tissue limit intravital imaging mostly to superficial brain regions, leaving deep-brain areas, such as the hippocampus, out of reach for optical microscopy. In this video, we show the preparation and implantation of the custom-made imaging window to enable chronic in vivo imaging of the dorsal hippocampal CA1 region in head-fixed behaving mice. The custom-made window is supplemented with an infusion cannula that allows targeted delivery of viral vectors and drugs to the imaging area. By combining this preparation with wide-field imaging, we performed a long-term recording of neuronal activity using a fluorescent calcium indicator from large subsets of neurons in behaving mice over several weeks. We also demonstrated the applicability of this preparation for voltage imaging with single-spike resolution. High-performance genetically encoded indicators of neuronal activity and scientific CMOS cameras allowed the recurrent visualization of subcellular morphological details of single neurons at high temporal resolution. We also discuss the advantages and potential limitations of the described method and its compatibility with other imaging techniques.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df_rank.index[0]]['abstract']"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lm_nlp_average_frequency_01.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
